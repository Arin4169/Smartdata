import pandas as pd
import numpy as np
import re
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from konlpy.tag import Okt
import streamlit as st
import matplotlib.font_manager as fm
import os
import platform

# 한글 자연어 처리를 위한 Okt 객체 초기화
okt = Okt()

# 기본 불용어 목록 (필요에 따라 추가 가능)
DEFAULT_STOPWORDS = ['이', '가', '은', '는', '을', '를', '에', '의', '과', '와', '에서', '로', '으로', '하다', '있다', '되다', '것']

# 불용어를 관리하는 함수
def get_stopwords():
    """세션에 저장된 불용어 목록을 반환하거나 기본 불용어 목록을 초기화합니다."""
    if 'stopwords' not in st.session_state:
        st.session_state.stopwords = DEFAULT_STOPWORDS.copy()
    return st.session_state.stopwords

def add_stopword(word):
    """불용어 목록에 새 단어를 추가합니다."""
    if 'stopwords' not in st.session_state:
        st.session_state.stopwords = DEFAULT_STOPWORDS.copy()
    
    # 공백으로 구분된 여러 단어를 처리
    words = [w.strip() for w in word.split() if w.strip()]
    for w in words:
        if w not in st.session_state.stopwords:
            st.session_state.stopwords.append(w)
    
    return st.session_state.stopwords

def reset_stopwords():
    """불용어 목록을 기본값으로 초기화합니다."""
    st.session_state.stopwords = DEFAULT_STOPWORDS.copy()
    return st.session_state.stopwords

def remove_stopword(word):
    """불용어 목록에서 단어를 제거합니다."""
    if 'stopwords' not in st.session_state:
        st.session_state.stopwords = DEFAULT_STOPWORDS.copy()
    
    if word in st.session_state.stopwords:
        st.session_state.stopwords.remove(word)
    
    return st.session_state.stopwords

# 한글 폰트 경로 찾기
def get_font_path():
    system_platform = platform.system()
    
    # 윈도우의 경우
    if system_platform == 'Windows':
        font_candidates = [
            'C:/Windows/Fonts/malgun.ttf',  # 맑은 고딕
            'C:/Windows/Fonts/gulim.ttc',   # 굴림
            'C:/Windows/Fonts/batang.ttc',  # 바탕
            'C:/Windows/Fonts/gothic.ttf'   # 고딕
        ]
    # macOS의 경우
    elif system_platform == 'Darwin':
        font_candidates = [
            '/Library/Fonts/AppleGothic.ttf',
            '/Library/Fonts/AppleSDGothicNeo.ttc',
            '/System/Library/Fonts/AppleSDGothicNeo.ttc'
        ]
    # 리눅스의 경우
    else:
        font_candidates = [
            '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',
            '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'
        ]
    
    # 존재하는 폰트 경로 반환
    for font_path in font_candidates:
        if os.path.exists(font_path):
            return font_path
    
    # 시스템에 설치된 폰트 중 한글 폰트 찾기
    korean_fonts = [f for f in fm.findSystemFonts() if any(name in f.lower() for name in ['gothic', 'gulim', 'batang', 'malgun', 'nanum', 'gungsuh'])]
    
    if korean_fonts:
        return korean_fonts[0]
    
    # 한글 폰트가 없는 경우
    st.warning("한글 폰트를 찾을 수 없습니다. 시각화에서 한글이 제대로 표시되지 않을 수 있습니다.")
    return None

# 시스템에서 사용 가능한 한글 폰트 경로 찾기
KOREAN_FONT_PATH = get_font_path()

def clean_text(text):
    """텍스트 전처리 함수"""
    if not isinstance(text, str):
        return ""
    
    # 특수문자 및 숫자 제거
    text = re.sub(r'[^\w\s]', ' ', text)
    text = re.sub(r'[0-9]', ' ', text)
    # 여러 공백을 하나로 치환
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

def extract_nouns(text):
    """명사 추출 함수"""
    clean = clean_text(text)
    
    if not clean:
        return []
    
    # 명사 추출
    nouns = okt.nouns(clean)
    
    # 현재 세션의 불용어 목록 가져오기
    stopwords = get_stopwords()
    
    # 불용어 및 한 글자 단어 제거
    nouns = [word for word in nouns if word not in stopwords and len(word) > 1]
    
    return nouns

def generate_wordcloud_data(df, column_name='review_content'):
    """워드클라우드 생성 데이터 준비 함수"""
    
    # 모든 리뷰 텍스트 결합
    all_reviews = ' '.join(df[column_name].dropna().astype(str))
    
    # 명사 추출
    all_nouns = extract_nouns(all_reviews)
    
    # 빈도수 계산
    word_count = Counter(all_nouns)
    
    # 상위 단어 추출
    top_words = dict(word_count.most_common(20))
    
    return word_count, top_words

def create_wordcloud(word_count, width=1200, height=800):
    """워드클라우드 시각화 함수"""
    
    # 워드클라우드 생성
    wc_params = {
        'width': width, 
        'height': height, 
        'background_color': 'white',
        'max_words': 100,
        'prefer_horizontal': 0.9
    }
    
    # 한글 폰트 경로가 있으면 추가
    if KOREAN_FONT_PATH:
        wc_params['font_path'] = KOREAN_FONT_PATH
    
    wc = WordCloud(**wc_params)
    
    # 단어 빈도수 데이터로 워드클라우드 생성
    wc.generate_from_frequencies(word_count)
    
    return wc

def simple_sentiment_analysis(df, column_name='review_content'):
    """간단한 감정 분석 함수"""
    
    # 긍정/부정 키워드 (실제로는 더 많은 단어와 더 정교한 방법 사용 필요)
    positive_words = ['좋다', '좋은', '좋아요', '만족', '최고', '추천', '맛있다', '편리하다', '빠르다', '친절하다']
    negative_words = ['나쁘다', '별로', '실망', '불만', '최악', '싫다', '아쉽다', '느리다', '불친절하다']
    
    # 감정 점수 계산 함수
    def get_sentiment_score(text):
        if not isinstance(text, str):
            return 0
        
        clean = clean_text(text)
        if not clean:
            return 0
        
        # 형태소 분석
        morphs = okt.morphs(clean)
        
        # 긍정/부정 점수 계산
        positive_score = sum(1 for word in morphs if word in positive_words)
        negative_score = sum(1 for word in morphs if word in negative_words)
        
        # 최종 점수 (-1: 매우 부정, 1: 매우 긍정)
        return (positive_score - negative_score) / (positive_score + negative_score + 0.001)
    
    # 리뷰별 감정 점수 계산
    df['sentiment_score'] = df[column_name].apply(get_sentiment_score)
    
    # 긍정/중립/부정 분류
    df['sentiment'] = df['sentiment_score'].apply(
        lambda x: '긍정' if x > 0.3 else ('부정' if x < -0.3 else '중립')
    )
    
    # 감정별 카운트
    sentiment_counts = df['sentiment'].value_counts().reset_index()
    sentiment_counts.columns = ['감정', '리뷰 수']
    
    return df, sentiment_counts

def analyze_options(df, option_column='option_info', count_column='count'):
    """옵션 분석 함수"""
    
    # 상위 10개 옵션 추출
    top_options = df.sort_values(by=count_column, ascending=False).head(10)
    
    return top_options 